# ğŸ’¬ RAG Chatbot with Context Memory

A conversational AI chatbot using Retrieval-Augmented Generation (RAG) with memory. Built with LangChain, OpenAI, FAISS, and Streamlit.

---

## ğŸ§  Features

- Context-aware Q&A from custom documents
- Uses FAISS vector index for fast semantic search
- Dual interface: Streamlit (frontend) + FastAPI (backend)
- LangChain memory for conversational flow

---

## ğŸ“ Project Structure

rag-chatbot/
â”œâ”€â”€ data/docs/ # Your document PDFs or text files
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ chatbot_app.py # Streamlit UI
â”‚ â””â”€â”€ api.py # FastAPI backend
â”œâ”€â”€ vector_store/ # FAISS index stored here

---

## ğŸš€ How to Run

### Install dependencies
bash
pip install -r requirements.txt

Start the chatbot (Streamlit UI)

streamlit run src/chatbot_app.py
Optional: Start backend API
uvicorn src.api:app --reload

ğŸ“š Data
Store your PDFs or .txt files in data/docs/
FAISS index will be created in vector_store/

ğŸ› ï¸ Tech Stack
Python, LangChain, OpenAI

FAISS (vector DB), Streamlit

FastAPI (backend), PyPDF / Text loaders